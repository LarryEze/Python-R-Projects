{"cells":[{"source":"![mobydick](mobydick.jpg)","metadata":{},"id":"b1309988-b429-4fb0-8c4c-193582dbec93","cell_type":"markdown"},{"source":"What are the most frequent words in Herman Melville's novel, Moby Dick, and how often do they occur?\n\nThe Data Science pipeline you'll build in this workspace can be used to visualize the word frequency distributions of any novel that you can find on Project Gutenberg. The natural language processing tools used here apply to much of the data that data scientists encounter as a vast proportion of the world's data is unstructured data and includes a great deal of text.","metadata":{},"id":"611e416c-70e7-478a-a3c8-e54f3fdb4a7f","cell_type":"markdown"},{"source":"# Import and download packages\nimport requests\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom collections import Counter\nnltk.download('stopwords')\n\n# Start coding here... ","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true},"executionTime":509,"lastSuccessfullyExecutedCode":"# Import and download packages\nimport requests\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom collections import Counter\nnltk.download('stopwords')\n\n# Start coding here... "},"id":"15b5f52f-fd9b-4f0e-9fcc-f7733022c7c0","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"True"},"metadata":{}}]},{"source":"# Get the Moby Dick HTML  \nr = requests.get('https://s3.amazonaws.com/assets.datacamp.com/production/project_147/datasets/2701-h.htm')\n\n# Set the correct text encoding of the HTML page\nr.encoding = 'utf-8'","metadata":{"executionTime":146,"lastSuccessfullyExecutedCode":"# Get the Moby Dick HTML  \nr = requests.get('https://s3.amazonaws.com/assets.datacamp.com/production/project_147/datasets/2701-h.htm')\n\n# Set the correct text encoding of the HTML page\nr.encoding = 'utf-8'","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"0b446c81-31ab-4ba3-b7d7-7d6e8144afee","execution_count":11,"outputs":[]},{"source":"# Extract the HTML from the request object\nhtml = r.text\n\n# Print the first 2000 characters in html\nprint(html[0:2000])","metadata":{"executionTime":38,"lastSuccessfullyExecutedCode":"# Extract the HTML from the request object\nhtml = r.text\n\n# Print the first 2000 characters in html\nprint(html[0:2000])","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"e147c2e4-1ecf-4a85-9ede-de29062a2ae1","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n\n<!DOCTYPE html\n   PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n   \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\" >\n\n<html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\">\n  <head>\n    <title>\n      Moby Dick; Or the Whale, by Herman Melville\n    </title>\n    <style type=\"text/css\" xml:space=\"preserve\">\n\n    body { background:#faebd0; color:black; margin-left:15%; margin-right:15%; text-align:justify }\n    P { text-indent: 1em; margin-top: .25em; margin-bottom: .25em; }\n    H1,H2,H3,H4,H5,H6 { text-align: center; margin-left: 15%; margin-right: 15%; }\n    hr  { width: 50%; text-align: center;}\n    .foot { margin-left: 20%; margin-right: 20%; text-align: justify; text-indent: -3em; font-size: 90%; }\n    blockquote {font-size: 100%; margin-left: 0%; margin-right: 0%;}\n    .mynote    {background-color: #DDE; color: #000; padding: .5em; margin-left: 10%; margin-right: 10%; font-family: sans-serif; font-size: 95%;}\n    .toc       { margin-left: 10%; margin-bottom: .75em;}\n    .toc2      { margin-left: 20%;}\n    div.fig    { display:block; margin:0 auto; text-align:center; }\n    div.middle { margin-left: 20%; margin-right: 20%; text-align: justify; }\n    .figleft   {float: left; margin-left: 0%; margin-right: 1%;}\n    .figright  {float: right; margin-right: 0%; margin-left: 1%;}\n    .pagenum   {display:inline; font-size: 70%; font-style:normal;\n               margin: 0; padding: 0; position: absolute; right: 1%;\n               text-align: right;}\n    pre        { font-family: times new roman; font-size: 100%; margin-left: 10%;}\n\n    table      {margin-left: 10%;}\n\na:link {color:blue;\n\t\ttext-decoration:none}\nlink {color:blue;\n\t\ttext-decoration:none}\na:visited {color:blue;\n\t\ttext-decoration:none}\na:hover {color:red}\n\n</style>\n  </head>\n  <body>\n<pre xml:space=\"preserve\">\n\nThe Project Gutenberg EBook of Moby Dick; or The Whale, by Herman Melville\n\nThis eBook is for the use of anyone anywh\n"}]},{"source":"# Create a BeautifulSoup object from the HTML\nsoup = BeautifulSoup(html, \"html.parser\")\n\n# Get the text out of the soup\ntext = soup.get_text()","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Create a BeautifulSoup object from the HTML\nsoup = BeautifulSoup(html, \"html.parser\")\n\n# Get the text out of the soup\ntext = soup.get_text()","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"0653c122-0193-4477-a0c7-b2a2419f74cf","execution_count":13,"outputs":[]},{"source":"# Create a tokenizer\ntokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n\n# Tokenize the text\ntokens = tokenizer.tokenize(text)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Create a tokenizer\ntokenizer = nltk.tokenize.RegexpTokenizer('\\w+')\n\n# Tokenize the text\ntokens = tokenizer.tokenize(text)","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"05b9326c-21d0-409e-8cf0-6ade798b537a","execution_count":14,"outputs":[]},{"source":"# Create a list called words containing all tokens transformed to lower-case\nwords = [token.lower() for token in tokens]\n\n# Print out the first 8 words / tokens \nwords[:8]","metadata":{"executionTime":48,"lastSuccessfullyExecutedCode":"# Create a list called words containing all tokens transformed to lower-case\nwords = [token.lower() for token in tokens]\n\n# Print out the first 8 words / tokens \nwords[:8]","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"c655f646-458d-4cf9-88c5-a7709e9067cb","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"['moby', 'dick', 'or', 'the', 'whale', 'by', 'herman', 'melville']"},"metadata":{}}]},{"source":"# Get the English stop words from nltk\nsw = nltk.corpus.stopwords.words('english')\n\n# Print out the first eight stop words\nsw[:8]","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"# Get the English stop words from nltk\nsw = nltk.corpus.stopwords.words('english')\n\n# Print out the first eight stop words\nsw[:8]","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"635de095-c05c-4d83-b4d3-66277e1cb087","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves']"},"metadata":{}}]},{"source":"# Create a list words_ns containing all words that are in words but not in sw\nwords_ns = [word for word in words if word not in sw]\n\n# Print the first 5 words_ns to check that  stop words are gone\nwords_ns[:5]","metadata":{"executionTime":120,"lastSuccessfullyExecutedCode":"# Create a list words_ns containing all words that are in words but not in sw\nwords_ns = [word for word in words if word not in sw]\n\n# Print the first 5 words_ns to check that  stop words are gone\nwords_ns[:5]","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"894d78cd-e791-4498-8016-c7398762ef97","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"['moby', 'dick', 'whale', 'herman', 'melville']"},"metadata":{}}]},{"source":"# Initialize a Counter object from our processed list of words\ncount = Counter(words_ns)\n\n# Store 10 most common words and their counts as top_ten\ntop_ten = count.most_common(10)\n\n# Print the top ten words and their counts\nprint(top_ten)","metadata":{"executionTime":61,"lastSuccessfullyExecutedCode":"# Initialize a Counter object from our processed list of words\ncount = Counter(words_ns)\n\n# Store 10 most common words and their counts as top_ten\ntop_ten = count.most_common(10)\n\n# Print the top ten words and their counts\nprint(top_ten)","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"29aa5560-7aa1-4e57-98de-72b3f0513d36","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"[('whale', 1246), ('one', 925), ('like', 647), ('upon', 568), ('man', 527), ('ship', 519), ('ahab', 517), ('ye', 473), ('sea', 455), ('old', 452)]\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}